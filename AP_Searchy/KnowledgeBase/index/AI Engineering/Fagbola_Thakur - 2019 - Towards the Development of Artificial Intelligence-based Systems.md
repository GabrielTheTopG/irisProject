- <span style="color:white">**Context**</span> self-aware and unmanned systems 

- <span style="color:steelblue">**Objective**</span> present and discuss key human-centered functional requirement specifications of emerging Artificial intelligence-based systems especially interpretability, explainability, fairness, transparency and security 

- <span style="color:seagreen">**Method**</span> qualitative approach was adopted by exploring several existing works on transparency, explainability, fairness trustworthiness and ethics of AI from a human-centric dimension capture 64 papers 

- <span style="color:Tomato">**Results**</span> Interpretability: This is described as the ability of humans to comprehend how a model works (Finale and Been, 2017). That is, given some algorithmic parameters, a human user is able to predict possible outcomes Zachary (2017) described an interpretable model as having two attributes: (i) transparent to humans; (ii) offers post-hoc explanations Explainability: This is the degree to which the internal structure of an AI-based systems be explained in a human understandable manner algorithmic fairness can be said to have been exhibited “if for two distinct individuals having the same general characteristic features but with differing sensitive attribute (for example, race/religion/gender etc), a learning model makes same decisions” (Toon and Indre, 2013). AI systems’ transparency denotes that AI systems should be comprehensible, intelligible and by humans irrespective of their level of expertise (Been et al., 2018). Safety/Security: Safety and security issues regarding AI-based systems revolve around concepts like safe AI for use by humans, verification, validation, self- awareness in adversary-prone environments. Goodman and Flaxman (2016) indicated that the datasets used for training and validating AI-based predictive systems can influence unethical and biased outcomes which in turn can reduce their trustworthiness. 

- <span style="color:MediumPurple">**Conclusion**</span> urrently, researches on usable and human-centered AI- based systems with practical applicability are still limited (Abdul, Vermeulen, Wang, Lim and Kankanhalli, 2018) 

---
> 
Summary

---

#Human #Centered #AI #Functional #Requirements 

The motivation for human-centered AI-based system development is borne out of usability and trust. A human- centered usable system is one that is trusted and safe to use

Based on the user and the context of use, tools can be developed to assess interpretability of AI systems or they are made interpretable by design (CASBS, 2018)

Transparency can be made possible at the instance of the whole model (simulatability), at the instance of each individual components (decomposability), and at the instance of the training procedure (algorithmic transparency) (Zachary, 2017).

