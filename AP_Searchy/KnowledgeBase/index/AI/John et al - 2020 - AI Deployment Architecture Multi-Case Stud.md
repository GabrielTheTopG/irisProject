- ## Deployment
#Deployment #ML #Workflow #Machine #Learning #ResearchStreams #AI #Engineering 
Based on our previous research [8], we developed a frame- work in which we identified five architectural alternatives for deploying AI ranging from centralized cloud to fully decentralized edge architectures. We validated the framework in four software-intensive embedded system companies and identified various challenges they face when deploying ML/DL models. In this paper, and to advance our research, we identify the key factors to be considered when selecting the optimal deployment architecture. For this, we conducted a follow- up study involving interviews and workshop in seven case companies in the embedded systems domain. Based on these findings, we develop an architectural selection framework in which we outline how prioritization and trade-offs between these results in a certain architecture.

- ## Deployment
#Deployment #ML #Workflow #Machine #Learning #ResearchStreams #AI #Engineering 
According to [12] and [13], developing, deploying and maintaining complex commercial ML-based system is a chal- lenging task. Most ML-based systems have strict latency requirements at inference stage [14]. Training-serving skew also results in sub-optimal model performance [15]. For the realistic implementation of ML, there is a need to consider and adapt well established SE practices which have been ignored or had a very narrow focus in ML literature [16] [17]. According to [7], software-intensive companies evolve through five stages based on their use of ML. They are (a) Experimentation and prototyping (b) Non-critical deployment (c) Critical deployment (d) Cascading deployment and (e) Autonomous ML components. During the experimentation and prototyping stage, the models do not proceed to real production.

- ## Architecture
#Architecture #Selection #Criteria #Deployment #ML #Workflow #Machine #Learning #ResearchStreams #AI #Engineering 
According to [12] and [13], developing, deploying and maintaining complex commercial ML-based system is a chal- lenging task. Most ML-based systems have strict latency requirements at inference stage [14]. Training-serving skew also results in sub-optimal model performance [15]. For the realistic implementation of ML, there is a need to consider and adapt well established SE practices which have been ignored or had a very narrow focus in ML literature [16] [17]. According to [7], software-intensive companies evolve through five stages based on their use of ML. They are (a) Experimentation and prototyping (b) Non-critical deployment (c) Critical deployment (d) Cascading deployment and (e) Autonomous ML components. During the experimentation and prototyping stage, the models do not proceed to real production.

- ## Architecture
#Architecture #Selection #Criteria #Deployment #ML #Workflow #Machine #Learning #ResearchStreams #AI #Engineering 
According to [12] and [13], developing, deploying and maintaining complex commercial ML-based system is a chal- lenging task. Most ML-based systems have strict latency requirements at inference stage [14]. Training-serving skew also results in sub-optimal model performance [15]. For the realistic implementation of ML, there is a need to consider and adapt well established SE practices which have been ignored or had a very narrow focus in ML literature [16] [17]. According to [7], software-intensive companies evolve through five stages based on their use of ML. They are (a) Experimentation and prototyping (b) Non-critical deployment (c) Critical deployment (d) Cascading deployment and (e) Autonomous ML components. During the experimentation and prototyping stage, the models do not proceed to real production.

- ## Architecture
#Architecture #Selection #Criteria #Deployment #ML #Workflow #Machine #Learning #ResearchStreams #AI #Engineering 
According to [12] and [13], developing, deploying and maintaining complex commercial ML-based system is a chal- lenging task. Most ML-based systems have strict latency requirements at inference stage [14]. Training-serving skew also results in sub-optimal model performance [15]. For the realistic implementation of ML, there is a need to consider and adapt well established SE practices which have been ignored or had a very narrow focus in ML literature [16] [17]. According to [7], software-intensive companies evolve through five stages based on their use of ML. They are (a) Experimentation and prototyping (b) Non-critical deployment (c) Critical deployment (d) Cascading deployment and (e) Autonomous ML components. During the experimentation and prototyping stage, the models do not proceed to real production.

