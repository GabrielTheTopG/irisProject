- ## Model
#Model #Experimentation #Machine #Learning #ResearchStreams #AI #Engineering 
A/B testing of models: During evolution, the improved model is deployed for operation. However, experience shows that models that perform better in training do not necessarily perform better in operations. Consequently, we need solutions, often variants of A/B testing, to ensure that the new model also performs better in deployment.

- ## Software
#Software #Quality  #ML #components #Software #Engineering #ResearchStreams #AI #Engineering 
Many customer problems solved by AI/ ML are only specified im- plicitly by their technical characteristics. Business goals are often not specified in a typical Software Engineering manner. Current AI software development processes loosely connect to business context, vaguely mention customer needs as “business understand- ing”, “model requirement” or “understanding of application domain”. The specifications of these attributes, as quality requirements or user stories should connect to business goals and reflect organiza- tional objectives. Moreover, they should be specific and measurable 1514Continuous Experimentation on Artificial Intelligence Software: A Research Agenda ESEC/FSE ’20, November 8–13, 2020, Virtual Event, USA Figure 1: A holistic view of continuous experiment loops for AI software development to guide downstream SE activities, such as design, database stor- age, model building and verification. Applied AI research focuses much on testing AI model quality attributes, such as accuracy, ex- plainability, fairness, dependability, or trustworthiness [19]. How- ever, these quality attributes are often taken for granted without questioning why customers need them and to what extent they should be achieved. Furthermore, research starts to look at different methodological approaches to identify, specify and include ethical requirements into AI software [17].

- ## Software
#Software #Quality  #ML #components #Software #Engineering #ResearchStreams #AI #Engineering 
Many customer problems solved by AI/ ML are only specified im- plicitly by their technical characteristics. Business goals are often not specified in a typical Software Engineering manner. Current AI software development processes loosely connect to business context, vaguely mention customer needs as “business understand- ing”, “model requirement” or “understanding of application domain”. The specifications of these attributes, as quality requirements or user stories should connect to business goals and reflect organiza- tional objectives. Moreover, they should be specific and measurable 1514Continuous Experimentation on Artificial Intelligence Software: A Research Agenda ESEC/FSE ’20, November 8–13, 2020, Virtual Event, USA Figure 1: A holistic view of continuous experiment loops for AI software development to guide downstream SE activities, such as design, database stor- age, model building and verification. Applied AI research focuses much on testing AI model quality attributes, such as accuracy, ex- plainability, fairness, dependability, or trustworthiness [19]. How- ever, these quality attributes are often taken for granted without questioning why customers need them and to what extent they should be achieved. Furthermore, research starts to look at different methodological approaches to identify, specify and include ethical requirements into AI software [17].

- ## Continuous
#Continuous #Experimentation #Software #Engineering #ResearchStreams #AI #Engineering 
Automated experimentation: Although the notion of automated experimentation is conceptually easy to un- derstand, actually realizing systems that can operate in this fashion is largely an open research challenge where little work is available.

