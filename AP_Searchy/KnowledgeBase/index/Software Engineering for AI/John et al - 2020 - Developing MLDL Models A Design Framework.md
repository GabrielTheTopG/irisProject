- ## Deployment
#Deployment #ResearchStreams #AI #Engineering 
Deploy on heterogeneous hardware: Finally, because of both cost and computational efficiency, embedded systems often use dedicated hardware solutions such as ASICs and FPGAs. Additionally, MD/DL models require huge amounts of parallel computation, both during train- ing and implementation, realised in e.g. GPUs. These exe- cution platforms use different development environments, programming languages, and execution paradigms. Em- bedded systems tend to have constraints on computational and storage resources as well as power consumption. Deploying ML/DL models on these types of hardware frequently requires engineering effort from the team as there are no generic solutions available.

- ## Continuous
#Continuous #Experimentation #Software #Engineering #ResearchStreams #AI #Engineering 
Automated experimentation: Although the notion of automated experimentation is conceptually easy to un- derstand, actually realizing systems that can operate in this fashion is largely an open research challenge where little work is available.

- ## DevOps
#DevOps #Integration #Software #Engineering #ResearchStreams #AI #Engineering 
Ops. Once the ML system component is operational in pro- duction environment, including the trained model, the system is continuously monitored to detect issues like performance degradation. Deployment to the production environment can be a manual, semi-automated or automated process that is performed after successful execution of tests in pre-production environments in development step. The Ops stage also ensures live testing of AI component by providing predictions whilst adhering to stringent latency requirement. At this step, devel- opers also collect information of how the model is performing based on live data. This information can be used to trigger retraining of models. Both Cases A and B have capability to monitor how the model is performing in production.

