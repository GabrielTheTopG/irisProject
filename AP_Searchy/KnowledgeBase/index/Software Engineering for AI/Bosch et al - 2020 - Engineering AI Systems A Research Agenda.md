- ## Storage
#Storage  #Computing #Infrastructure #Provisioning #ResearchStreams #AI #Engineering 
Storage and computing infrastructure: Although many assume that all ML/DL deployments operate in the cloud, our interaction with industry shows that many companies build up internal storage and computing infrastructure because of legal constraints, cost or quality attributes. Developing these infrastructures, for example for the development of autonomous driving solutions, is a major engineering and research challenge. Typically collection and storing of data is organized centrally on the enterprise level, while development of AI solutions is distributed over several development teams.

- ## Deployment
#Deployment #ResearchStreams #AI #Engineering 
â€¢ Deployment infrastructure: Independent of the use of centralized or federated learning approaches, models still need to be deployed in systems in the field. As most case study companies have adopted or plan to soon adopt DevOps, it is important for a deployment infrastructure to reliably deploy subsequent versions of models, measure their performance, raise warnings and initiate rollbacks in the case of anomalous behaviour. This infrastructure is by necessity of a distributed nature as it requires functionality both centrally as well as in each system that is part of the DevOps approach. Deployment of MD/DL models may require substantial change in the overall architecture of the system.

- ## Deployment
#Deployment #ResearchStreams #AI #Engineering 
Deploy on heterogeneous hardware: Finally, because of both cost and computational efficiency, embedded systems often use dedicated hardware solutions such as ASICs and FPGAs. Additionally, MD/DL models require huge amounts of parallel computation, both during train- ing and implementation, realised in e.g. GPUs. These exe- cution platforms use different development environments, programming languages, and execution paradigms. Em- bedded systems tend to have constraints on computational and storage resources as well as power consumption. Deploying ML/DL models on these types of hardware frequently requires engineering effort from the team as there are no generic solutions available.

- ## DataOps
#DataOps #Data #Engineering #ResearchStreams #AI #Engineering 
DataOps: Although considered a buzzword by some, DataOps raises the concern of managing everything data with the same structured and systematic approach as that we manage software with in a traditional DevOps context. As typical companies ask their data scientists to spend north of 95% of their time on cleaning, pre-processing and managing data, there is a significant opportunity to reduce this overhead by generating, distributing and storing data smarter in the development process. DataOps requires high levels of automation, which requires align- ment and standardization in order to achieve continuous value delivery.

- ## Synthetic
#Synthetic #Data #Generation #Data #Engineering #ResearchStreams #AI #Engineering 
Data generation for machine learning: Traditional ML/DL model development requires data scientists to spend significant amounts of time to convert available data sets that often are intended for human consumption into data sets that are usable for machine learning. In au- tonomously improving systems, the data that is generated by the system needs to be machine interpretable without any human help. How to accomplish this, though, is an open research question.

- ## ML
#ML #Model #Quality #Factors #Machine #Learning #ResearchStreams #AI #Engineering 
Quality attributes: In data science, the key challenge is to achieve high accuracy, recall or other metrics directly related to the ML performance of the machine learning model. In an AI engineering context, however, several other quality attributes become relevant including the computation performance, in terms of the number of inferences per time unit the system can manage, the 5real-time properties, robustness of the system in case of data outside the scope of training set, etc. Ensuring satisfactory adherence to the quality requirements on the ML components in the system is a research challenge that is far from resolved

- ## Model
#Model #Experimentation #Machine #Learning #ResearchStreams #AI #Engineering 
A/B testing of models: During evolution, the improved model is deployed for operation. However, experience shows that models that perform better in training do not necessarily perform better in operations. Consequently, we need solutions, often variants of A/B testing, to ensure that the new model also performs better in deployment.

- ## Continuous
#Continuous #Experimentation #Software #Engineering #ResearchStreams #AI #Engineering 
Automated experimentation: Although the notion of automated experimentation is conceptually easy to un- derstand, actually realizing systems that can operate in this fashion is largely an open research challenge where little work is available.

